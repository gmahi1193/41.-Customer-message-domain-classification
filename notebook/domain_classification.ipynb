{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Haptik is one of the world's largest conversational AI platforms. It is a personal assistant mobile app, powered by a combination of artificial intelligence and human assistance. It has its domain in multiple fields including customer support, feedback, order status and live chat.\n",
    "\n",
    "We have with us the dataset of Haptik containing the messages it receives from the customers and which topic(class) the messages refer to.\n",
    "\n",
    "We need to create a model predicting which class a particular message belongs to using NLP.\n",
    "Additionally you can also try to use techniques like LSA (Latent Semantic Analysis) and LDA (Latent Dirichlet Allocation) to assign topics to new messages.\n",
    "\n",
    "\n",
    "# About the dataset\n",
    "\n",
    "The original data looked like:\n",
    "![dataset](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b566/984701e4-eb7e-4127-97cb-614776062232/file.PNG)\n",
    "\n",
    "\n",
    "\n",
    "The dataset consisted of `message` column along with the different column associated with the topic they could associated with it. \n",
    "\n",
    "We have combined the instances of different topic into a single column called cateogory. The snapshot of the data you will be working on:\n",
    "\n",
    "![](T_Data.PNG)\n",
    "\n",
    "\n",
    "The dataset has details of 40000 messages You need to predict the category.\n",
    "\n",
    "For final submission purposes, following is the label encoding of the category column:\n",
    "```python\n",
    "\n",
    "{0: 'casual',\n",
    " 1: 'food',\n",
    " 2: 'movies',\n",
    " 3: 'nearby',\n",
    " 4: 'other',\n",
    " 5: 'recharge',\n",
    " 6: 'reminders',\n",
    " 7: 'support',\n",
    " 8: 'travel'}\n",
    "```\n",
    "\n",
    "### About the dataset\n",
    "\n",
    "\n",
    "A zipped file containing the following items is given:\n",
    "\n",
    "- `train.csv`\n",
    "\n",
    "The data file `train.csv` contains the `40000` instances with the `2` features including the target feature(target feature is not encoded).\n",
    "\n",
    "- `test.csv`\n",
    "\n",
    "The datafile `test.csv` contains the `10000`instances with the `1` feature excluding the target feature.\n",
    "\n",
    "- `sample_submission.csv` \n",
    "\n",
    "Explained under the `Submission` sub-heading\n",
    "\n",
    "\n",
    "- `domain_classification_student_template.ipynb`\n",
    "\n",
    "A template notebook explaining the task breakdown to solve the given problem statement\n",
    "\n",
    "\n",
    "## Submission\n",
    "\n",
    "After training the model on `train.csv` data, the learner has to predict the target feature of the `test.csv` data using the trained model. The learner has to then submit a csv file with the predicted feature.\n",
    "\n",
    "Sample submission file(`sample_submission.csv`) is given to you as a reference to the format expected when you submit \n",
    "\n",
    "\n",
    "## Evaluation metrics\n",
    "\n",
    "For this particular dataset we are using simple `F1 score`(average=\"macro\") as the evaluation metric. \n",
    "\n",
    "Submissions will be evaluated based on [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) as per the below threshold.\n",
    "\n",
    "|Your `f1_score` score| Points earned for the Task|\n",
    "|-----|-----|\n",
    "|`f1_score`> 0.7|100% of the available points|\n",
    "| 0.7 <= `f1_score` <= 0.68 |80% of the available points|\n",
    "| 0.68 <= `f1_score` <= 0.66 |70% of the available points|\n",
    "|`f1_score` <= 0.65|No points earned|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix, f1_score\n",
    "\n",
    "import gensim\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we will load the dataset and perform a basic cleaning in order to simplify our futher steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7am everyday</td>\n",
       "      <td>reminders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chocolate cake</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>closed mortice and tenon joint door dimentions</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train eppo kelambum</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yesterday i have cancelled the flight ticket</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            message   category\n",
       "MID                                                           \n",
       "0                                      7am everyday  reminders\n",
       "1                                    chocolate cake       food\n",
       "2    closed mortice and tenon joint door dimentions    support\n",
       "3                               train eppo kelambum     travel\n",
       "4      yesterday i have cancelled the flight ticket     travel"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/train_data.csv', index_col = 'MID')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the Text Analytics concepts we need to convert this textual data into vectors so that we can apply machine learning algorithms to them. In this task we will now employ a normal TF-IDF vectorizer to vectorize the message column and label encode the category column, essentially making it a classification problem. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['category'] = le.fit_transform(data['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['category'], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer().set_params(stop_words = 'english')\n",
    "tfidf.fit_transform(X_train)\n",
    "X_train = tfidf.transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tasks we have cleaned the data and converted the textual data into numbers in order to enable us to apply machine learning models. In this task we will apply Random forest classifier , MultinomialNB, SVM model and Logistic regression onto the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7360972727004778 is the f1 score of the logistic regression model\n",
      "0.6468078449174866 is the f1 score of the Naive Bayes model\n",
      "0.7494978602566456 is the f1 of the LinearSVC model\n"
     ]
    }
   ],
   "source": [
    "# Implementing Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=0)\n",
    "log_reg.fit(X_train,y_train)\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "log_f1 = f1_score(y_test,y_pred_log, average='macro')\n",
    "print (str(log_f1)+(\" is the f1 score of the logistic regression model\"))\n",
    "\n",
    "# Implementing Multinomial NB model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "nb_f1 = f1_score(y_test,y_pred_nb,average='macro')\n",
    "print (str(nb_f1)+(\" is the f1 score of the Naive Bayes model\"))\n",
    "\n",
    "\n",
    "# Implementing Linear SVM model\n",
    "lsvm = LinearSVC(random_state=0)\n",
    "lsvm.fit(X_train, y_train)\n",
    "y_pred_lsvm = lsvm.predict(X_test)\n",
    "lsvm_f1 = f1_score(y_test,y_pred_lsvm,average='macro')\n",
    "print (str(lsvm_f1)+(\" is the f1 of the LinearSVC model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best score is given by LinearSVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how well our models run on test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 4, ..., 0, 4, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on test data\n",
    "\n",
    "test_data = pd.read_csv(\"../data/test_data.csv\")\n",
    "\n",
    "X_test_data = tfidf.transform(test_data['message'])\n",
    "\n",
    "# res = rb.predict(X_test_data)\n",
    "res = lsvm.predict(X_test_data)\n",
    "res\n",
    "# Code ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
